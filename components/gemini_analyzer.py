import google.generativeai as genai
import streamlit as st
from typing import List, Dict, Any
from PIL import Image
import time
import sys
import os
import traceback

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.error_handler import ErrorHandler
from utils.image_converter import ImageConverter
from config import Config

class GeminiAnalyzer:
    def __init__(self):
        self.error_handler = ErrorHandler()
        self.image_converter = ImageConverter()
        self.model = None
        self._initialize_model()

    def _initialize_model(self):
        """
        Gemini APIã®åˆæœŸåŒ–
        """
        if not self.error_handler.validate_api_key():
            st.error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return

        try:
            genai.configure(api_key=Config.GEMINI_API_KEY)
            self.model = genai.GenerativeModel(Config.GEMINI_MODEL)
            # åˆæœŸåŒ–æˆåŠŸã®ãƒ­ã‚°ã¯è¡¨ç¤ºã—ãªã„ï¼ˆUIã‚’ã‚¯ãƒªãƒ¼ãƒ³ã«ä¿ã¤ãŸã‚ï¼‰
            pass
        except Exception as e:
            st.error(f"Gemini APIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            st.error(f"APIã‚­ãƒ¼ã®æœ€åˆã®10æ–‡å­—: {Config.GEMINI_API_KEY[:10] if Config.GEMINI_API_KEY else 'ãªã—'}...")
            self.error_handler.handle_error(e, "Gemini APIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")

    def analyze_images(self, images: List[Image.Image], prompt: str = Config.ANALYSIS_PROMPT) -> str:
        """
        ç”»åƒãƒªã‚¹ãƒˆã‚’è§£æã—ã¦çµæœã‚’è¿”ã™
        """
        if not self.model:
            return "ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚API ã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        try:
            def _analyze():
                # ç”»åƒæ•°ã‚’ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°æ™‚ã®ã¿è¡¨ç¤ºï¼‰
                # st.info(f"ğŸ“„ {len(images)}ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’è§£æä¸­...")

                # ç”»åƒã‚µã‚¤ã‚ºã‚’ç¢ºèªã—ã¦å¿…è¦ã«å¿œã˜ã¦ãƒªã‚µã‚¤ã‚º
                processed_images = []
                for i, img in enumerate(images):
                    # å¤§ãã™ãã‚‹ç”»åƒã¯ãƒªã‚µã‚¤ã‚º
                    resized_img = self.image_converter.resize_image_if_needed(img)
                    processed_images.append(resized_img)

                # Gemini APIã¸é€ä¿¡
                response = self.model.generate_content([prompt] + processed_images)

                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ç¢ºèª
                if response and hasattr(response, 'text'):
                    return response.text
                else:
                    st.error("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                    return None

            result = self.error_handler.retry_on_failure(
                _analyze,
                custom_error_msg="Gemini APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ"
            )

            return result if result else "è§£æçµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

        except Exception as e:
            # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
            st.error(f"ç”»åƒè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.error(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            st.text("ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:")
            st.code(traceback.format_exc())
            return "è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

    def analyze_batch(self, batch_data: Dict[str, Any], progress_bar=None) -> str:
        """
        ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
        """
        file_name = batch_data['file_name']
        batch_number = batch_data['batch_number']
        total_batches = batch_data['total_batches']
        images = batch_data['images']

        if total_batches > 1:
            st.info(f"å‡¦ç†ä¸­: {file_name} - ãƒãƒƒãƒ {batch_number}/{total_batches}")

        result = self.analyze_images(images)

        if progress_bar:
            progress_bar.progress(batch_number / total_batches)

        return result

    def combine_batch_results(self, results: List[str], file_name: str) -> str:
        """
        è¤‡æ•°ã®ãƒãƒƒãƒçµæœã‚’çµ±åˆ
        """
        if len(results) == 1:
            return results[0]

        combined = f"## ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}\n\n"
        combined += "### çµ±åˆè§£æçµæœ\n\n"

        for i, result in enumerate(results, 1):
            if len(results) > 1:
                combined += f"#### ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i}\n"
            combined += result + "\n\n"

        return combined

    def analyze_all_batches(self, all_batches: List[Dict[str, Any]]) -> Dict[str, str]:
        """
        ã™ã¹ã¦ã®ãƒãƒƒãƒã‚’è§£æã—ã¦çµæœã‚’è¿”ã™
        """
        results_by_file = {}
        total_batches = len(all_batches)

        progress_bar = st.progress(0)
        progress_text = st.empty()

        for idx, batch_data in enumerate(all_batches):
            file_name = batch_data['file_name']

            progress_text.text(
                Config.SUCCESS_MESSAGES['page_progress'].format(idx + 1, total_batches)
            )

            result = self.analyze_batch(batch_data)

            if file_name not in results_by_file:
                results_by_file[file_name] = []
            results_by_file[file_name].append(result)

            progress_bar.progress((idx + 1) / total_batches)
            time.sleep(0.1)

        progress_bar.empty()
        progress_text.empty()

        final_results = {}
        for file_name, batch_results in results_by_file.items():
            final_results[file_name] = self.combine_batch_results(batch_results, file_name)

        return final_results